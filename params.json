{"name":"Standardized-velvet-assembly-report","tagline":"Automatically exported from code.google.com/p/standardized-velvet-assembly-report","body":"# Frequently Asked Questions\r\n## Where can I find more information on N50 length?\r\nThis, my most popular blog entry ever, discusses N50 in detail:\r\n\r\nhttp://jermdemo.blogspot.com/2008/11/calculating-n50-from-velvet-output.html\r\n\r\n## Why is the N50 reported in your report different from the one I see in the Log file produced by Velvet\r\n\r\nThe N50 in the Log file is in kmer units. The N50 in the report is in bp.\r\n\r\n## I added kmer-1 to the N50 in the Log file and did not arrive at the number in your report. What is going on here?\r\n\r\nYou can't add kmer-1 to the kmer-N50 to arrive at the bp-N50. The math doesn't work like that. You need to convert all the contig lengths to bp and then calculate N50.\r\n\r\n## I calculated the N50 from my contigs.fa file and got a different answer from kmer-N50 or your bp-N50. What the hell is wrong with this?\r\n\r\nThe contigs.fa contains by default only those contigs longer than 2kmers. Contigs shorter than that are considered spurious. So the N50 of sequences in your contigs.fa file will be considerably higher than that calculated from using the stats.txt file.\r\n\r\n## Why do I get different read usage numbers when I specify -useamos in generateAssemblyStats.pl? ==\r\n\r\nI think this is usually a side effect of allowing N's in your input sequences. Velvet will convert these to A's. If there is another read with a real A at that position Velvet will consider the N-posing-as-A read as used and the honest-A read as unused. The point being you should just leave out or trim sequences with Ns.\r\n\r\n## I don't understand what should I use as input - contigs or reads? ==\r\n\r\nUse quality trimmed reads as input.\r\n\r\n## What should I use to quality trim my reads?\r\nNikhil Joshi's Trim will handle soft trimming with pair mate widows\r\n\r\nhttp://wiki.bioinformatics.ucdavis.edu/index.php/Trim.pl\r\n\r\nJoseph Fass's TrimBWAStyle is a slightly different algorithm\r\n\r\nhttp://wiki.bioinformatics.ucdavis.edu/index.php/TrimBWAstyle.pl\r\n\r\n## How should I use your report?\r\n\r\nThis report simply provides a way of visualizing the effect of kmer and cvCut on your assemblies.\r\n\r\nIf you find that your assemblies \"converge\" or arrive at roughly the same results, then you can choose one arbitrarily and move on. If you find that your assemblies are scattered across the landscape of size, contig count, read usage, and N50, then you will need to consider what levels of stringency and sensitivity you are willing to accept.\r\n\r\nAny assembly will be composed of:\r\n\r\n  * correct contigs\r\n  * fragmented contigs\r\n  * chimeric contigs\r\n  * spurious contigs\r\n\r\nand may suffer from:\r\n\r\n  * missing contigs\r\n\r\n\r\nI would consider chimeras and spurious contigs to be distinguished by length - spurious contigs are an artifact of the debruijn method and are very short. I don't think chimeras are very common in Velvet compared to other assemblers - any ambiguity normally results in fragments.\r\n\r\nVelvet assemblies performed under high stringency (high kmer, high cvCut) conditions will minimize chimeric, fragmented and spurious contigs at the expense of more missing contigs.\r\n\r\nTo validate a de-novo short read assembly, especially a transcriptome which by its very nature will never form long contigs, you need to decide whether you are willing to accept some bad with the good or insist on just the good and get less of it. This is a classic signal-to-noise problem.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}